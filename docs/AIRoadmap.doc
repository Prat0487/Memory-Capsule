I'll create a comprehensive roadmap for AI integration based on the provided documentation. The user wants a positive, detailed response without apologies. I'll focus on concrete steps, timelines, and implementation details.

From the docs, I can see that AI-Powered Memory Enhancement is a P0 feature (high priority) along with Basic Sharing Capabilities (which we've already implemented).

Let me think about a structured roadmap that follows best practices for AI integration:

Initial research and platform selection
POC/prototype development
Core API integration
Frontend integration
Testing and optimization
Advanced features
Production deployment
I'll make this specific to their memory platform with concrete deliverables for each phase.

AI Integration Roadmap for Memory Capsule
Based on your platform's requirements and the documents provided, here's a comprehensive roadmap for implementing AI enhancements to your memory platform:

Phase 1: Foundation (Week 1-2)
Set up Google Vertex AI integration

// Install required packages
npm install @google-cloud/vertexai

// Create AI service config file
// services/ai-service/src/config/ai-config.js
export const vertexConfig = {
  projectId: process.env.GOOGLE_CLOUD_PROJECT_ID,
  location: 'us-central1',
  apiEndpoint: 'us-central1-aiplatform.googleapis.com'
};

Copy

Apply

Implement basic narrative generation API

// services/ai-service/src/index.js
import { VertexAI } from '@google-cloud/vertexai';
import { vertexConfig } from './config/ai-config';

const vertex = new VertexAI(vertexConfig);

export const generateNarrative = async (description, imageUrl) => {
  const model = vertex.preview.getGenerativeModel({
    model: 'gemini-1.5-pro',
  });
  
  const prompt = `Generate a reflective, nostalgic 3-4 sentence narrative about this memory. 
                 Description provided: ${description}. 
                 Focus on emotional significance and personal meaning.`;
  
  const result = await model.generateContent({
    contents: [{ role: 'user', parts: [{ text: prompt }] }]
  });
  
  return result.response.text();
};

Copy

Apply

Phase 2: Frontend Integration (Week 3)
Add AI toggle to memory creation form

// services/frontend/src/pages/CreateMemoryPage.jsx
const [useAI, setUseAI] = useState(true);

// In your form JSX
<div className="mt-4 flex items-center">
  <input
    type="checkbox"
    id="ai-enhance"
    checked={useAI}
    onChange={(e) => setUseAI(e.target.checked)}
    className="h-4 w-4 text-blue-600 rounded"
  />
  <label htmlFor="ai-enhance" className="ml-2 text-gray-700">
    Generate AI narrative for this memory
  </label>
</div>

Copy

Apply

Enhance memory creation flow

// In your form submission handler
const handleSubmit = async (e) => {
  // ...existing code
  
  const formData = {
    // ...existing fields
    enhanceWithAI: useAI
  };
  
  // Submit to backend
};

Copy

Apply

Phase 3: Image Analysis Integration (Week 4)
Add image content analysis capabilities

// services/ai-service/src/index.js
export const analyzeImage = async (imageUrl) => {
  const model = vertex.preview.getGenerativeModel({
    model: 'gemini-1.5-pro-vision',
  });
  
  const result = await model.generateContent({
    contents: [{
      role: 'user',
      parts: [
        { text: 'Describe what you see in this image, focusing on people, places, objects, and mood.' },
        { fileData: { mimeType: 'image/jpeg', fileUri: imageUrl } }
      ]
    }]
  });
  
  return result.response.text();
};

Copy

Apply

Create middleware to process uploads with AI

// services/blockchain-service/src/middleware/ai-processor.js
import { generateNarrative, analyzeImage } from '../../ai-service/src/index.js';

export const processMemoryWithAI = async (req, res, next) => {
  if (!req.body.enhanceWithAI) {
    return next();
  }
  
  try {
    // Get image URL from IPFS hash
    const imageUrl = `https://ipfs.io/ipfs/${req.body.ipfsHash}`;
    
    // Generate both image analysis and narrative in parallel
    const [imageAnalysis, narrative] = await Promise.all([
      analyzeImage(imageUrl),
      generateNarrative(req.body.description, imageUrl)
    ]);
    
    // Add to request body
    req.body.aiAnalysis = imageAnalysis;
    req.body.narrative = narrative;
    
    next();
  } catch (error) {
    console.error('AI processing error:', error);
    // Continue without AI if there's an error
    next();
  }
};

Copy

Apply

Phase 4: Advanced Features & Optimization (Week 5-6)
Add sentiment analysis to memories

export const analyzeSentiment = async (text) => {
  const model = vertex.preview.getGenerativeModel({
    model: 'gemini-1.5-pro',
  });
  
  const result = await model.generateContent({
    contents: [{
      role: 'user',
      parts: [{ 
        text: `Analyze the emotional sentiment of this text and return a single word 
              sentiment (happy, nostalgic, reflective, joyful, sad, etc): "${text}"` 
      }]
    }]
  });
  
  return result.response.text().trim();
};

Copy

Apply

Implement memory tagging and categorization

export const generateTags = async (description, imageAnalysis) => {
  const combinedText = `${description} ${imageAnalysis}`;
  
  const model = vertex.preview.getGenerativeModel({
    model: 'gemini-1.5-pro',
  });
  
  const result = await model.generateContent({
    contents: [{
      role: 'user',
      parts: [{ 
        text: `Generate 3-5 tags for this memory content. Return only the tags as a 
              comma-separated list: "${combinedText}"` 
      }]
    }]
  });
  
  return result.response.text().split(',').map(tag => tag.trim());
};

Copy

Apply

Phase 5: Production Deployment (Week 7-8)
Implement caching and performance optimizations

// Add response caching to avoid repeated AI calls
import NodeCache from 'node-cache';

const aiCache = new NodeCache({ stdTTL: 86400 }); // 24-hour cache

export const generateNarrativeWithCache = async (description, imageUrl) => {
  const cacheKey = `narrative_${hashString(description)}_${hashString(imageUrl)}`;
  
  // Check cache first
  const cachedResult = aiCache.get(cacheKey);
  if (cachedResult) {
    return cachedResult;
  }
  
  // Generate new result
  const result = await generateNarrative(description, imageUrl);
  
  // Store in cache
  aiCache.set(cacheKey, result);
  
  return result;
};

Copy

Apply

Add user feedback collection and model improvement

// services/ai-service/src/feedback.js
export const collectNarrativeFeedback = async (memoryId, narrativeId, rating, userComment) => {
  // Store feedback in database for model improvement
  const feedback = {
    memoryId,
    narrativeId,
    rating,
    userComment,
    timestamp: new Date()
  };
  
  await saveFeedbackToDatabase(feedback);
  
  // If rating is poor, trigger regenration with feedback context
  if (rating < 3) {
    await regenerateNarrative(memoryId, userComment);
  }
  
  return { success: true };
};

Copy

Apply

This roadmap is structured to deliver incremental value at each phase while building toward a comprehensive AI-enhanced memory platform. The implementation follows a modular approach that aligns with your existing architecture, making it maintainable and expandable as your platform grows to serve millions of users.

ok now provide detail implementation for Phase 1 week 1-2




Agentic chat
— completed

Agentic context
— 1 new item
For Phase 1 (Foundation, Week 1-2), I need to provide a detailed implementation plan that covers setting up Google Vertex AI integration and implementing the basic narrative generation API. I'll go beyond just showing code snippets and provide comprehensive guidance on what to do, how to do it, and why specific approaches are being taken.

I'll structure this as:

Environment setup
Service creation
API implementation
Testing and validation
Configuration management
I'll be detailed, positive, and thorough in explaining the reasoning behind each step.

Phase 1 Implementation: AI Foundation (Week 1-2)
Here's a detailed implementation plan for establishing your AI foundation:

Week 1: Environment Setup and Basic Integration
Day 1-2: Google Cloud and Vertex AI Setup
# Install Google Cloud CLI
npm install -g @google-cloud/cli

Copy

Execute

# Authenticate with Google Cloud
gcloud auth login

Copy

Execute

# Create service account for AI operations
gcloud iam service-accounts create memory-ai-service \
  --description="Service account for Memory Capsule AI" \
  --display-name="Memory AI Service"

Copy

Execute

# Generate and download service account key
gcloud iam service-accounts keys create ./vertex-ai-key.json \
  --iam-account=memory-ai-service@your-project-id.iam.gserviceaccount.com

Copy

Execute

Create an environment configuration file:

export const environment = {
  projectId: process.env.GOOGLE_CLOUD_PROJECT_ID || 'your-project-id',
  keyFilename: process.env.GOOGLE_APPLICATION_CREDENTIALS || './vertex-ai-key.json',
  location: process.env.VERTEX_LOCATION || 'us-central1',
  apiEndpoint: process.env.VERTEX_ENDPOINT || 'us-central1-aiplatform.googleapis.com',
  modelName: process.env.VERTEX_MODEL || 'gemini-1.5-pro',
  maxRetries: 3,
  timeoutMs: 30000
};

Copy

Apply

services\ai-service\src\config\environment.js
Day 3-4: AI Service Structure
Create the AI service module structure:

import { VertexAI } from '@google-cloud/vertexai';
import { environment } from '../config/environment.js';

// Create singleton for Vertex client
let vertexInstance = null;

export const getVertexClient = () => {
  if (!vertexInstance) {
    vertexInstance = new VertexAI({
      project: environment.projectId,
      location: environment.location,
      apiEndpoint: environment.apiEndpoint,
      keyFilename: environment.keyFilename
    });
  }
  
  return vertexInstance;
};

export const getGenerativeModel = (modelName = environment.modelName) => {
  const vertex = getVertexClient();
  return vertex.preview.getGenerativeModel({
    model: modelName,
    generationConfig: {
      maxOutputTokens: 256,
      temperature: 0.4,
      topP: 0.8,
      topK: 40
    }
  });
};

Copy

Apply

services\ai-service\src\clients\vertex-client.js
Day 5: Prompt Engineering and Templates
export const narrativePrompts = {
  basic: (description) => `
    Generate a reflective, emotional narrative about this memory.
    
    Context: ${description}
    
    Create 3-4 sentences that capture the emotional significance of this memory.
    Focus on the feelings, connections, and meaning rather than just describing what happened.
    Use a warm, thoughtful tone that evokes nostalgia and appreciation.
    
    Narrative:
  `,
  
  detailed: (description, imageContext = '') => `
    Create a meaningful narrative for a personal memory.
    
    Memory description: ${description}
    ${imageContext ? `Visual elements: ${imageContext}` : ''}
    
    Generate a thoughtful 4-5 sentence narrative that:
    - Captures the emotional essence of this moment
    - Reflects on its significance in a life journey
    - Uses sensory details to make the memory vivid
    - Maintains a personal, intimate perspective
    - Avoids clichés and generic statements
    
    Narrative:
  `
};

Copy

Apply

services\ai-service\src\templates\prompts.js
Week 2: Core AI Functionality Implementation
Day 1-2: Basic Narrative Generation
import { getGenerativeModel } from '../clients/vertex-client.js';
import { narrativePrompts } from '../templates/prompts.js';
import { logger } from '../utils/logger.js';

export const generateBasicNarrative = async (description) => {
  try {
    const model = getGenerativeModel();
    const prompt = narrativePrompts.basic(description);
    
    logger.info(`Generating narrative for memory: ${description.substring(0, 30)}...`);
    
    const result = await model.generateContent({
      contents: [{ role: 'user', parts: [{ text: prompt }] }]
    });
    
    // Extract the generated text from the response
    const generatedText = result.response.text().trim();
    
    // Post-process to clean up potential formatting issues
    const narrative = generatedText
      .replace(/^Narrative:|\s*Narrative:\s*/i, '')  // Remove any "Narrative:" prefix
      .replace(/\n{2,}/g, '\n')                     // Normalize line breaks
      .trim();
    
    logger.info('Narrative generated successfully');
    return narrative;
  } catch (error) {
    logger.error('Error generating narrative:', error);
    
    // Provide a fallback response rather than failing
    return "A cherished moment captured in time, preserving the emotions and connections that make life meaningful.";
  }
};

Copy

Apply

services\ai-service\src\functions\narrative-generator.js
Day 3-4: Image Integration (Preparation)
import axios from 'axios';

export const validateImageUrl = async (url) => {
  try {
    const response = await axios.head(url, { timeout: 5000 });
    return response.status >= 200 && response.status < 300;
  } catch (error) {
    return false;
  }
};

export const getIpfsGatewayUrl = (ipfsHash, attemptNumber = 0) => {
  const gateways = [
    'https://ipfs.io/ipfs/',
    'https://cloudflare-ipfs.com/ipfs/',
    'https://gateway.pinata.cloud/ipfs/',
    'https://dweb.link/ipfs/'
  ];
  
  // Use modulo to cycle through gateways if we exceed the list
  const gatewayIndex = attemptNumber % gateways.length;
  return `${gateways[gatewayIndex]}${ipfsHash}`;
};

Copy

Apply

services\ai-service\src\utils\image-utils.js
Day 5: API Endpoint Creation and Testing
import express from 'express';
import cors from 'cors';
import { generateBasicNarrative } from './functions/narrative-generator.js';
import { validateImageUrl, getIpfsGatewayUrl } from './utils/image-utils.js';
import { logger } from './utils/logger.js';

const app = express();
app.use(cors());
app.use(express.json());

// Health check endpoint
app.get('/health', (req, res) => {
  res.status(200).json({ status: 'ok' });
});

// Narrative generation endpoint
app.post('/api/narrative', async (req, res) => {
  try {
    const { description, ipfsHash } = req.body;
    
    if (!description) {
      return res.status(400).json({ 
        success: false, 
        error: 'Memory description is required' 
      });
    }
    
    // First attempt at generating basic narrative
    const narrative = await generateBasicNarrative(description);
    
    res.status(200).json({
      success: true,
      narrative
    });
  } catch (error) {
    logger.error('Error in narrative API:', error);
    res.status(500).json({ 
      success: false, 
      error: 'Failed to generate narrative' 
    });
  }
});

const PORT = process.env.PORT || 3005;
app.listen(PORT, () => {
  logger.info(`AI service running on port ${PORT}`);
});

export {
  generateBasicNarrative
};

Copy

Apply

services\ai-service\src\index.js
Implementation Testing
Create a simple test script to validate your implementation:

import { generateBasicNarrative } from '../src/functions/narrative-generator.js';

const testNarrativeGeneration = async () => {
  const sampleDescriptions = [
    "My daughter's first birthday party with family gathered around the cake",
    "Hiking to the summit of Mount Rainier last summer",
    "Our family reunion at the beach house in 2022"
  ];
  
  console.log('Testing narrative generation...\n');
  
  for (const description of sampleDescriptions) {
    console.log(`Description: ${description}`);
    const narrative = await generateBasicNarrative(description);
    console.log(`Generated Narrative: ${narrative}\n`);
  }
};

testNarrativeGeneration().catch(console.error);

Copy

Apply

services\ai-service\test\test-narrative.js
Implementation Benefits
This implementation provides several key advantages:

Modular Design: The separation of clients, templates, and functions creates a maintainable codebase that can evolve as your AI needs grow.

Resilience: Error handling and fallbacks ensure your user experience never breaks, even if AI services encounter issues.

Performance Optimization: The singleton pattern for Vertex client prevents repetitive initialization overhead.

Configuration Flexibility: Environment variables allow for easy deployment across development, staging, and production environments.

Prompt Engineering: Separating prompts into templates makes it easy to experiment with different approaches to narrative generation without changing application logic.

By the end of these two weeks, you'll have a fully functional AI service integrated into your Memory Capsule platform, providing the foundation for more advanced features in subsequent phases.

